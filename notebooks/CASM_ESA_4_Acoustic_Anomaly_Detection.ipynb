{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4218b705",
   "metadata": {},
   "source": [
    "## Computational Analysis of Sound and Music\n",
    "\n",
    "# ESA 4 - Acoustic Anomaly Detection\n",
    "\n",
    "Dr.-Ing. Jakob Abe√üer, jakob.abesser@idmt.fraunhofer.de\n",
    "\n",
    "**Last update:** 03.06.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dded3d3a",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "In this notebook, we use a small dataset for acoustic anomaly detection.\n",
    "We will implement two methods:\n",
    "- a **traditional machine learning approach** using **distribution modeling** to detect anomalies as **outliers**\n",
    "- a **deep learning-based method** using an **autoencoder** and the **reconstruction error** to detect anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f181fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1612f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import os\n",
    "import matplotlib\n",
    "import librosa\n",
    "import matplotlib.pyplot as pl\n",
    "import platform\n",
    "import IPython.display as ipd\n",
    "import wget\n",
    "import zipfile\n",
    "import glob\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b858785",
   "metadata": {},
   "source": [
    "## Dataset download & pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcb4a66",
   "metadata": {},
   "source": [
    "The **anomaly_mini** dataset includes audio recordings from the MIMII dataset (https://zenodo.org/records/3384388):\n",
    "\n",
    "*Purohit, H., Tanabe, R., Ichige, K., Endo, T., Nikaido, Y., Suefusa, K., & Kawaguchi, Y. (2019). MIMII Dataset: Sound Dataset for Malfunctioning Industrial Machine Investigation and Inspection (public 1.0) [Data set]. 4th Workshop on Detection and Classification of Acoustic Scenes and Events (DCASE 2019 Workshop), New York, USA.*\n",
    "\n",
    "Here's a part of the official description: *\"This dataset is a sound dataset for malfunctioning industrial machine investigation and inspection (MIMII dataset). It contains the sounds generated from four types of industrial machines, i.e. valves, pumps, fans, and slide rails. Each type of machine includes seven individual product models, and the data for each model contains normal sounds (from 5000 seconds to 10000 seconds) and anomalous sounds (about 1000 seconds)\"*\n",
    "\n",
    "Concetely, the **anomaly_mini** dataset includes from the **6_db_valve.zip** file.\n",
    "It has **20 2.5s audio clips** for training (representing the **normal state**) and **5 2.5s clips** each as test data for the normal and anomaly classes, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe70caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('anomaly_mini.zip'):\n",
    "    print('Please wait a couple of seconds ...')\n",
    "    wget.download('https://github.com/machinelistening/machinelistening.github.io/blob/master/anomaly_mini.zip?raw=true', \n",
    "                      out='anomaly_mini.zip', bar=None)\n",
    "    print('anomaly_mini.zip downloaded successfully ...')\n",
    "else:\n",
    "    print('Files already exist!')\n",
    "    \n",
    "if not os.path.isdir('anomaly_mini'):\n",
    "    print(\"Let's unzip the file ... \")\n",
    "    assert os.path.isfile('anomaly_mini.zip')\n",
    "    with zipfile.ZipFile('anomaly_mini.zip', 'r') as f:\n",
    "        f.extractall('.')\n",
    "    assert os.path.isdir('anomaly_mini')\n",
    "    print(\"All done :)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1183b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample rate\n",
    "fs = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36751d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dir_dataset = 'anomaly_mini'\n",
    "fn_wav_list = glob.glob(os.path.join(dir_dataset, '*.wav'))\n",
    "\n",
    "is_train = []\n",
    "class_id = []\n",
    "\n",
    "for fn_wav in fn_wav_list:\n",
    "    class_id.append(int('_anomaly_' in fn_wav))\n",
    "    is_train.append(int('train' in fn_wav))\n",
    "\n",
    "n_files = len(fn_wav_list)\n",
    "\n",
    "# let's check\n",
    "for i in range(n_files):\n",
    "    print(f\"file {i+1}: {fn_wav_list[i]} (class = {class_id[i]}, is_train={is_train[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d1a86e",
   "metadata": {},
   "source": [
    "Let's listen to some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (0, 3,6,9,12,15,17)\n",
    "for i in idx:\n",
    "    x, fs = librosa.load(fn_wav_list[i])\n",
    "    print(os.path.basename(fn_wav_list[i]))\n",
    "    ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534a702",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3535637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_melspec(fn_wav, n_bins=128):\n",
    "    \"\"\" Compute Mel spectrogram with logarithmic magnitude scaling \n",
    "    Args:\n",
    "        fn_wav (str): WAV file name\n",
    "        n_bins (int): Number of Mel frequency bins\n",
    "    Returns:\n",
    "        mel_spec (2d np.ndarray): Mel spectrogram (n_bins x n_frames)\n",
    "    \"\"\"\n",
    "    x, fs = librosa.load(fn_wav, mono=True, sr=44100)\n",
    "    S = librosa.feature.melspectrogram(y=x, sr=fs, n_mels=n_bins, fmax=fs/2)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    return S_dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096caaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = []\n",
    "for fn_wav in fn_wav_list:\n",
    "    feat.append(compute_melspec(fn_wav))\n",
    "feat = np.array(feat)\n",
    "feat = np.expand_dims(feat, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e60440",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Feature matrix shape: {feat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce605cbf",
   "metadata": {},
   "source": [
    "For the machine learning based approach, we represent each audio clip not as a 2D spectrogram but as a 1D feature vector. In particular, we use the time-average over the entire spectrogram as feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc1c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat.shape)\n",
    "\n",
    "# here, we can remove the channel dimension\n",
    "feat_1d = (np.squeeze(np.mean(feat, axis=2)))\n",
    "print(feat_1d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a1ceb",
   "metadata": {},
   "source": [
    "**Observation**: This is a shape we already know from the first lectures on Machine learning: **number of data instances x number of features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7131ab",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa349a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = np.array(is_train, dtype=bool)\n",
    "is_test = np.logical_not(is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfe450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1d_train = feat_1d[is_train, :]\n",
    "X_1d_test = feat_1d[is_test, :]\n",
    "X_train = feat[is_train, :, :, :]\n",
    "X_test = feat[is_test, :, :, :]\n",
    "\n",
    "class_id = np.array(class_id)\n",
    "\n",
    "y_train = class_id[is_train]\n",
    "y_test = class_id[is_test]\n",
    "\n",
    "# Data standardization\n",
    "scaler = StandardScaler().fit(X_1d_train)\n",
    "X_1d_train = scaler.transform(X_1d_train)\n",
    "X_1d_test = scaler.transform(X_1d_test)\n",
    "\n",
    "\n",
    "print(f\"X_1d_train shape {X_1d_train.shape}\")\n",
    "print(f\"X_1d_test shape {X_1d_test.shape}\")\n",
    "print(f\"X_train shape {X_train.shape}\")\n",
    "print(f\"X_test shape {X_test.shape}\")\n",
    "\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b618e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=8 \n",
    "n_epochs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b7acef",
   "metadata": {},
   "source": [
    "## Approach 1: Distribution Modeling & Outlier Detection\n",
    "\n",
    "In the first appraoch, we use a Gaussian mixture model to model the distribution of our **normal training examples**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d37406",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=2, random_state=42)\n",
    "gmm.fit(X_1d_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07119d41",
   "metadata": {},
   "source": [
    "As a second step, we'll compute the likelihood for each test sample, that it was drawn from the learnt distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = gmm.score_samples(X_1d_test)\n",
    "\n",
    "# at this point, we computed the log-likelihood score, it is higher for \n",
    "# samples drawn from the learnt distribution (normal examples) and lower\n",
    "# for samples outside of this distribution (anomaly examples)\n",
    "\n",
    "# in order to use it as detection function (where values above a threshold are assigned \n",
    "# to the anomaly class), we need to inverse it\n",
    "scores -= np.min(scores)\n",
    "scores /= np.max(scores)\n",
    "scores = 1 - scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a8d440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature space visualization after dimensionality reduction using \n",
    "# Principal Component Analysis (PCA)\n",
    "pca = PCA().fit(X_1d_train)\n",
    "X_1d_train_pca = pca.transform(X_1d_train)\n",
    "X_1d_test_pca = pca.transform(X_1d_test)\n",
    "\n",
    "pl.figure(figsize=(6,3))\n",
    "pl.plot(X_1d_train_pca[:, 0], X_1d_train_pca[:, 1], 'ok', label='Training (normal)')\n",
    "pl.plot(X_1d_test_pca[y_test==0, 0], X_1d_test_pca[y_test==0, 1], 'og', label='Test (normal)')\n",
    "pl.plot(X_1d_test_pca[y_test==1, 0], X_1d_test_pca[y_test==1, 1], 'dr', label='Test (anomaly)')\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fa5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(4,3))\n",
    "pl.title('Distribution modeling approach')\n",
    "pl.plot(y_test, scores, 'ko')\n",
    "pl.xlabel('True label (0 = normal, 1 = anomaly)')\n",
    "pl.ylabel('Anomaly score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed768ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "roc_auc = roc1 = roc_auc_score(y_test, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39db611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(4,4))\n",
    "pl.plot(fpr, tpr, \n",
    "    color=\"darkorange\",\n",
    "    lw=2,\n",
    "    label=\"ROC curve\",\n",
    ")\n",
    "pl.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.05])\n",
    "pl.xlabel(\"False Positive Rate\")\n",
    "pl.ylabel(\"True Positive Rate\")\n",
    "pl.title(f\"Receiver operating characteristic, AUC = {roc_auc}\")\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute AUC ROC metric\n",
    "print(y_test)\n",
    "roc1 = roc_auc_score(y_test, scores)\n",
    "print(f\"AUC ROC = {roc1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357eb4f8",
   "metadata": {},
   "source": [
    "**Observation**: Compute the static average over all spectrogram frames does not seem to be a good feature vector for anomaly detection. The main reason is that we lose all information about the temporal dynamics of the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ead51e",
   "metadata": {},
   "source": [
    "## Approach 2: Autoencoder + Reconstruction Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267e04db",
   "metadata": {},
   "source": [
    "### Neural Network Architecture\n",
    "\n",
    "We'll create a **convolutional autoencoder** which has a **encoder** that compresses the input to a latent (bottleneck) representation and a **decoder** which maps this representation back to the original signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5084c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def create_autoencoder(input_shape):\n",
    "    # Encoder\n",
    "    input_img = Input(shape=input_shape)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    #x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    #x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "    #x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(input_shape[2], (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Autoencoder\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d96278",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model = create_autoencoder(input_shape=X_train.shape[1:])\n",
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3361b62",
   "metadata": {},
   "source": [
    "For training, we only need to provide the training data (no labels!) as **both input and output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18717f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data to [0, 1] due to the sigmoid layer\n",
    "min_ = np.min(X_train)\n",
    "range_ = np.max(X_train) - np.min(X_train)\n",
    "\n",
    "X_train -= min_\n",
    "X_train /= range_\n",
    "X_test -= min_\n",
    "X_test /= range_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model.fit(X_train, X_train, batch_size=2, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814d0746",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d2a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred = ae_model.predict(X_test)\n",
    "\n",
    "# compute mean squared error (MSE) as reconstruction error for all test samples\n",
    "ae_score = np.mean(np.square(X_test - X_test_pred), axis=(1, 2, 3)) \n",
    "\n",
    "print(y_test, ae_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480ae5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(4,3))\n",
    "pl.title('Autoencoder approach')\n",
    "pl.plot(y_test, ae_score, 'ko')\n",
    "pl.xlabel('True label (0 = normal, 1 = anomaly)')\n",
    "pl.ylabel('Anomaly score (reconstruction error)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d35d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute false positive rate (FPR) and true positive rate (TPR) for different \n",
    "# decision thresholds to be applied on the \"scores\"\n",
    "fpr, tpr, _ = roc_curve(y_test, ae_score)\n",
    "roc_auc = roc1 = roc_auc_score(y_test, ae_score)\n",
    "print(f\"ROC AUC = {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce174733",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(4,4))\n",
    "pl.plot(fpr, tpr, \n",
    "    color=\"darkorange\",\n",
    "    lw=2,\n",
    "    label=\"ROC curve\",\n",
    ")\n",
    "pl.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "pl.xlim([0.0, 1.0])\n",
    "pl.ylim([0.0, 1.05])\n",
    "pl.xlabel(\"False Positive Rate\")\n",
    "pl.ylabel(\"True Positive Rate\")\n",
    "pl.title(f\"Receiver operating characteristic, AUC = {roc_auc}\")\n",
    "pl.legend(loc=\"lower right\")\n",
    "pl.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
