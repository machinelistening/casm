{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4218b705",
   "metadata": {},
   "source": [
    "# Computational Analysis of Sound and Music\n",
    "\n",
    "# MIR 2 - Harmonic Analysis\n",
    "\n",
    "Dr.-Ing. Jakob AbeÃŸer, jakob.abesser@idmt.fraunhofer.de\n",
    "\n",
    "**Last update:** 29.04.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e690b683",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "In this notebook, you will learn how to implement a simple **chord recognition** algorithm using **binary template matching**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6063c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5b1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import wget\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa517f8",
   "metadata": {},
   "source": [
    "Let's make sure we have the dataset we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in ['c_g_am_f_piano.wav', 'c_g_am_f_violin.wav']:\n",
    "    if not os.path.isfile(fn):\n",
    "        print('Please wait a couple of seconds ...')\n",
    "        wget.download(f'https://github.com/machinelistening/machinelistening.github.io/blob/master/{fn}?raw=true', \n",
    "                          out=fn, bar=None)\n",
    "        print(f'{fn} downloaded successfully ...')\n",
    "    else:\n",
    "        print('Files already exist!')\n",
    "print('All files ready :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b858785",
   "metadata": {},
   "source": [
    "## Check the audio files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee71160b",
   "metadata": {},
   "source": [
    "In this notebook, we'll use two audio files of a simple **4-chord sequence**:\n",
    " - C major\n",
    " - G major\n",
    " - A minor\n",
    " - F major\n",
    " \n",
    " This chord sequence is often referred to as \"I -> V -> vi -> IV\" and is the most popular chord sequence according to https://www.hooktheory.com/theorytab/common-chord-progressions/1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d30d0",
   "metadata": {},
   "source": [
    "The sequence is played once with **piano** and once with **violins**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in ['c_g_am_f_piano.wav', 'c_g_am_f_violin.wav']:\n",
    "    x, fs = librosa.load(fn)\n",
    "    ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91e803",
   "metadata": {},
   "source": [
    "## Chords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a76c775",
   "metadata": {},
   "source": [
    "A **chord** in music is a combination of three or more notes played simultaneously or in succession. \n",
    "\n",
    "It is the basic building block of harmony and can create a sense of tension or release in a piece of music.\n",
    "\n",
    "Here, we distinguish between the most basic **3-note chord types**: \n",
    "\n",
    "- major chords (e.g. the first chord in the audio examples: C-major)\n",
    "- minor chords (e.g. the third chord in the audio examples: A-minor)\n",
    "\n",
    "Each chord type includes a **root**, the **third** interval above the root, and the **firth** interval above the root.\n",
    "\n",
    "Each **interval** has a particular number of **semitones**:\n",
    "\n",
    "- Major chord\n",
    "  - major third interval -> **4 semitones** above the root\n",
    "  - (pure) fifth interval -> **7 semitones** above the root\n",
    "\n",
    "- Minor chord\n",
    "  - minor third interval -> **3 semitones** above the root\n",
    "  - (pure) fifth interval -> **7 semitones** above the root\n",
    "\n",
    "To summarize, each of the two chord types we consider includes 3 notes, which have a different pitch distance to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e039dd2",
   "metadata": {},
   "source": [
    "## Templates\n",
    "\n",
    "Now, we want to represent chords as **binary templates** on a **12-dimensional chroma vector**\n",
    "\n",
    "Remember, the corresponding chroma values are C, C#, D, D#, E etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ff191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_template = np.zeros(12, dtype=int)\n",
    "minor_template = np.zeros(12, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967e047",
   "metadata": {},
   "source": [
    "For the **C-major** template, we need to set three of these 12 values to one:\n",
    "  - root note (C) -> index 0 \n",
    "  - \"major third\" interval (E) -> index 4\n",
    "  - \"fifth\" interval (G) -> index 7\n",
    "  \n",
    "Similarly, for the **C-minor** template, we need to set three of these 12 values to one:\n",
    "  - root note (C) -> index 0 \n",
    "  - \"minor third\" interval (Eb) -> index 3\n",
    "  - \"fifth\" interval (G) -> index 7\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fca7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "major_template[0] = 1\n",
    "major_template[4] = 1\n",
    "major_template[7] = 1\n",
    "print(f\"Major chord - binary template: {major_template}\")\n",
    "\n",
    "minor_template[0] = 1\n",
    "minor_template[3] = 1\n",
    "minor_template[7] = 1\n",
    "print(f\"Minor chord - binary template: {minor_template}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4337d49e",
   "metadata": {},
   "source": [
    "**Note**: The binary tempaltes are a **strong simplification** as we assume that \n",
    "  - only the fundamental frequency of each tone is audible (which is not true, as we know there are additional harmonics, which end up in different chroma bins)\n",
    "  - each tone is equally loud (which is also rareley the case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc8db3",
   "metadata": {},
   "source": [
    "## Semitone rotation\n",
    "\n",
    "As we have 12 possible chroma values (C, C#, D, ...), we can rotate these templates accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b2420",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_major = np.zeros((12, 12), dtype=int)\n",
    "templates_minor = np.zeros((12, 12), dtype=int)\n",
    "for i in range(0, 12):\n",
    "    templates_major[i, :] = np.roll(major_template, i)\n",
    "    templates_minor[i, :] = np.roll(minor_template, i)\n",
    "    \n",
    "print(f\"All 12 major templates in the rows of \\n {templates_major}\")\n",
    "print(f\"All 12 minor templates in the rows of \\n{templates_minor}\")\n",
    "\n",
    "# Finally, let's stack all templates\n",
    "templates = np.vstack((templates_major, templates_minor))\n",
    "print(templates.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b88caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a list of chord labels\n",
    "chord_labels = []\n",
    "for chord_type in ('major', 'minor'):\n",
    "    for chord_root in ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']:\n",
    "        chord_labels.append(f\"{chord_root}-{chord_type}\")\n",
    "print(chord_labels)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101eeffc",
   "metadata": {},
   "source": [
    "## Chromagram\n",
    "\n",
    "Let's compute the chromagrams of the piano and violin recording and visualize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(8,6))\n",
    "for f, fn in enumerate([('Piano', 'c_g_am_f_piano.wav'), \n",
    "                        ('Violins', 'c_g_am_f_violin.wav')]):\n",
    "    y, sr = librosa.load(fn[1], mono=True, sr=44100)\n",
    "    chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "    \n",
    "    pl.subplot(2,1,f+1)\n",
    "    pl.title(fn[0])\n",
    "    librosa.display.specshow(chroma_cens, y_axis='chroma', x_axis='time', ax=pl.gca())\n",
    "pl.tight_layout()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a934e66",
   "metadata": {},
   "source": [
    "## Template Matching\n",
    "\n",
    "Now we want to match our binary templates against the computed chromagrams to see **which chords are most likely at a particular time in the audio recording**.\n",
    "\n",
    "Following ..., we use the **inner product of normalized vectors** as similarity vector between a **binary chord template** and a **chromagram** frame. We first normalize the chromagram and the chord templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbe8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('c_g_am_f_piano.wav', mono=True, sr=44100)\n",
    "chroma_cens = librosa.feature.chroma_cens(y=y, sr=sr)\n",
    "\n",
    "# normalize chromagram by dividing each frame (column) by its 2-norm\n",
    "chroma_cens_norm = chroma_cens / np.sqrt(np.sum(chroma_cens**2, axis=0))\n",
    "\n",
    "# normalize the chord templates in a similar way (but per row!)\n",
    "templates_norm = templates / np.sqrt(np.sum(templates**2, axis=1))[:, np.newaxis]\n",
    "\n",
    "# Now we compute the similarity of all chromagram frames with all major types efficiently:\n",
    "\n",
    "# (1) chromagram dimension: 12 x N_frames\n",
    "print(chroma_cens_norm.shape)\n",
    "\n",
    "# (2) templates dimension N_chords x 12\n",
    "print(templates_norm.shape)\n",
    "\n",
    "# Therefore, we can use a matrix multiplication\n",
    "chord_similarity = np.matmul(templates_norm, chroma_cens_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c970b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize our chord detection results\n",
    "pl.figure(figsize=(10,6))\n",
    "pl.imshow(chord_similarity, aspect=\"auto\", origin=\"lower\", interpolation=\"None\")\n",
    "pl.yticks(np.arange(24), chord_labels)\n",
    "pl.ylabel('Chord')\n",
    "pl.xlabel('Frame')\n",
    "pl.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2fba49",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Remember our initial chord progression? \n",
    " - C major\n",
    " - G major\n",
    " - A minor\n",
    " - F major\n",
    " \n",
    " **Looks like our template matching approach works well for this example :)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4320b",
   "metadata": {},
   "source": [
    "## Further steps\n",
    "\n",
    "- read more about the template matching approach at https://www.audiolabs-erlangen.de/resources/MIR/FMP/C5/C5S2_ChordRec_Templates.html#Template-Based-Pattern-Matching\n",
    "\n",
    "- try to define other templates, e.g. for seventh chords like \"major-seventh\" or \"dominant-seventh\"\n",
    "- apply the approach on other music styles / recordings with multiple instruments playing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
