{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c49dcbd",
   "metadata": {},
   "source": [
    "# Computational Analysis of Sound and Music\n",
    "\n",
    "# A2 - Audio & Time-Frequency Representations\n",
    "\n",
    "Dr.-Ing. Jakob AbeÃŸer, jakob.abesser@idmt.fraunhofer.de\n",
    "\n",
    "**Last update:** 26.03.2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f84403",
   "metadata": {},
   "source": [
    "**Outline**\n",
    "\n",
    "In this notebook, you will learn \n",
    " - how to load and process audio files in Python\n",
    " - how to sonify and visualize waveforms\n",
    " - how to compute and visualize the STFT, Mel Spectrogram, and CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfc180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wget\n",
    "import os\n",
    "import matplotlib\n",
    "import librosa\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as pl\n",
    "import platform\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc1729",
   "metadata": {},
   "source": [
    "### *(Platform-independent Code)*\n",
    "\n",
    "**HINT**: if you want to write Python scripts that work on multiple platforms (like Windows, Linux etc.), you can use ```platform.platform()``` to figure out automatically, which platform your Python code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594bc099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check current platform\n",
    "print(platform.platform())\n",
    "\n",
    "# use if/else conditions\n",
    "if \"Windows\" in platform.platform():\n",
    "    dir_audio = 'C:/audio_files'\n",
    "else:\n",
    "    dir_audio = '/my_server/audio_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdac900",
   "metadata": {},
   "source": [
    "### Get audio example files\n",
    "\n",
    "This script loads 2 audio files that we need here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb54e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('piano.wav') or not os.path.isfile('bird.wav'):\n",
    "    for fn in ('piano.wav', 'bird.wav'):\n",
    "        wget.download('https://github.com/machinelistening/machinelistening.github.io/blob/master/{}?raw=true'.format(fn), \n",
    "                      out=fn, bar=None)\n",
    "else:\n",
    "    print('Files already exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3865b",
   "metadata": {},
   "source": [
    "### File paths\n",
    "\n",
    "When working with multiple audio files, it is a good practice to treat directories and filenames separately and use ```os.path.join``` to combine both to absolute filenames. This command uses the correct delimiter signs for all operating systems (Windows, MacOS, Linux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) define path to the directory that contains the audio files (WAV format)\n",
    "# TIP: under Windows, it is also recommended to use '/', e.g. 'C:/my_audio_files'\n",
    "dir_wav = ''  # here, we use the same directory as the notebook is in\n",
    "\n",
    "# this could also look like\n",
    "# dir_wav = 'c:/audio_files'\n",
    "\n",
    "# 2) create absolute path of audio file (directory + filename)\n",
    "# os.path.join takes care of the correct delimiter signs\n",
    "# - Linux / MacOSx: \"/\"\n",
    "# - Windows: \"\\\\\"\n",
    "\n",
    "fn_wav = os.path.join(dir_wav, 'bird.wav')  # original filename: 416529__inspectorj__bird-whistling-single-robin-a_2s\n",
    "print(fn_wav)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbbc7f2",
   "metadata": {},
   "source": [
    "### Loading audio files\n",
    "\n",
    "- first check librosa documentation: https://librosa.org/doc/main/generated/librosa.load.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3dceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) use the sample rate of the file, load stereo if needed\n",
    "x, fs = librosa.load(fn_wav)\n",
    "\n",
    "print(\"Sample vector shape:\", x.shape)  # 1D numpy array, mono\n",
    "print(\"Sample rate [Hz]\", fs)\n",
    "print(f\"Audio duration (seconds): {len(x)/fs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2) you could also enforce another sample rate\n",
    "fs_fix = 44100\n",
    "x, fs = librosa.load(fn_wav, sr=fs_fix)  # in this case, the signal is upsampled to a higher sample rate\n",
    "\n",
    "print(x.shape)  # ! increase of sampling rate (upsampling) -> more samples!\n",
    "print(fs) # ! fix sample rate was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c5327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3) if you have a stereo file, you can enforce one channel audio (mono)\n",
    "# x, fs = librosa.load(fn_wav, mono=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdf8d7",
   "metadata": {},
   "source": [
    "### Sonification\n",
    "\n",
    "Let's listen to our example audio file (birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d760c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b8e56",
   "metadata": {},
   "source": [
    "### Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94344262",
   "metadata": {},
   "source": [
    "Our audio signal is roughly 2.06 s long. Let's extract the first 1.5 seconds of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de7d07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_end = int(fs*1.5)\n",
    "x_first_1_5_s = x[:sample_end]\n",
    "print(f\"Our segment has a duration of {len(x_first_1_5_s)/fs} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f247f132",
   "metadata": {},
   "source": [
    "### Waveform Visualization\n",
    "\n",
    "Let's plot our waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce33eb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,2))\n",
    "pl.plot(x)\n",
    "pl.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c62993a",
   "metadata": {},
   "source": [
    "**Observation**: the x-axis just shows the sample number so far, this is not informative without the sample rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee9b49",
   "metadata": {},
   "source": [
    "#### Create time axis\n",
    "\n",
    "The sample rate in Hz defines, how many audio samples exist per second. If we compute the inverse ($1/f_\\mathrm{s}$), we get the duration of each sample in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a912ce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(x)\n",
    "print(\"Number of samples:\", number_of_samples)\n",
    "\n",
    "seconds_per_sample = 1/fs\n",
    "print(\"Duration [seconds] of one sample\", seconds_per_sample)  # on audio sample corresponds to ~22.7 ms\n",
    "\n",
    "# let's create a numpy array with the physical time of each audio sample\n",
    "frames_in_seconds = np.arange(number_of_samples)*seconds_per_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55bf25a",
   "metadata": {},
   "source": [
    "let's plot the signal again, this time with an interpretable x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27599420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pl.figure(figsize=(10,2))\n",
    "pl.plot(frames_in_seconds, x)\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('Amplitude')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc645181",
   "metadata": {},
   "source": [
    "### Spectrogram using Short-Time Fourier Transform (STFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58c4eab",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.stft.html?highlight=stft#librosa-stft\n",
    "\n",
    "The most important parameters are \n",
    "  - **win_length** - this is the size of our analysis window (in samples)\n",
    "  - **hop_length** - this is the hop size of our analysis window (in samples), usually this is chosen to be half the window size\n",
    "  - (**n_fft**) - this is the used \"FFT size\", which can be bigger than the **win_length** (but should be a power of two, such that the Fast Fourier Transform (FFT) algorithm can be used internally)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the STFT\n",
    "n_fft = 2048\n",
    "hop_length = 1024\n",
    "X = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)  # using the default values: n_fft=2048, \n",
    "print(\"Shape of STFT:\", X.shape)  # we get n_fft//2 - 1 bins, the reason is that the STFT has a \n",
    "                                  # symmetric structure and we can discard several entries\n",
    "print(\"Data type of STFT:\", X.dtype)  # ! the STFT is complex and has a magnitude and a phase\n",
    "\n",
    "# We'll focus on the magnitude of the STFT\n",
    "S = np.abs(X)\n",
    "print(\"Shape of the magnitude spectrogram:\", S.shape)\n",
    "print(\"Data type of the magnitude spectrogram:\", S.dtype)  # ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot it\n",
    "pl.figure(figsize=(6,4))\n",
    "pl.imshow(S, aspect=\"auto\")\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce83b3",
   "metadata": {},
   "source": [
    "There a several **problems** with this plot:\n",
    "  1. the frequency axis is flipped (lower frequencies are shown on top and higher frequencies are shown at the bottom)\n",
    "  2. only the loudest frequency components are visible  \n",
    "  3. we want the axes to show the frequency in Hz (y-axis) and the time in seconds (x-axis), at the moment, we only see the frequency bin (y-axis) of the STFT and the frame number (x-axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c378a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 1.) use \"origin\" parameter for imshow()\n",
    "pl.figure(figsize=(6,4))\n",
    "pl.imshow(S, aspect=\"auto\", origin=\"lower\")\n",
    "pl.colorbar()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 2.) apply logarithmic compression to the magnitude values -> this converts the linear magnitudes to decibels (dB)\n",
    "S_dB = librosa.amplitude_to_db(S, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b870c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize=(6,4))\n",
    "pl.imshow(S_dB, aspect=\"auto\", origin=\"lower\")\n",
    "pl.colorbar(format='%+2.0f dB')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4403fe34",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "1.  also parts with lower magnitudes are now better visible\n",
    "2.  the value range shifts from [0, 70] to [-80, 0], this is because of the logarithmic compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Issue 3.) define maximum frequency, and maximum time value\n",
    "f_max = fs/2  # Nyquist frequency\n",
    "t_max = number_of_samples / fs\n",
    "print(f_max)\n",
    "print(t_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(6,4))\n",
    "# use \"extent\" parameter to define actual range of values along x / y acis\n",
    "pl.imshow(S_dB, aspect=\"auto\", origin=\"lower\", extent=[0, t_max, 0, f_max])\n",
    "pl.xlabel('Time [s]')\n",
    "pl.ylabel('Frequency [Hz]')\n",
    "pl.colorbar(format='%+2.0f dB')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb0257d",
   "metadata": {},
   "source": [
    "**Practical Alternative**\n",
    "\n",
    "As an alternative, we can use the build-in visualization function ```specshow``` of librosa, which allows to visualize STFT spectrograms, Mel spectrograms, and others.\n",
    "\n",
    "Check the documentation for more info: https://librosa.org/doc/main/generated/librosa.display.specshow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7006ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots()\n",
    "# note the keyword \"mel\", which indicates that a mel frequency axis is used\n",
    "img = librosa.display.specshow(S_dB, x_axis='time', y_axis='hz', sr=fs, ax=ax, cmap='viridis')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='STFT Magnitude Spectrogram (specshow)')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a15326",
   "metadata": {},
   "source": [
    "### Mel-Spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c52d77",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.feature.melspectrogram.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **n_mels** - number of Mel frequency bands (commonly: 64 or 128)\n",
    "  - **win_length** - see above (STFT)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **n_fft** - see above (STFT)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24501885",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = librosa.feature.melspectrogram(y=x, n_fft=2048, hop_length=1024, n_mels=128)  \n",
    "print(\"Shape of Mel spectrogram:\", M.shape)  # frequency x time: we get n_mels frequency bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540c840",
   "metadata": {},
   "source": [
    "Let's visualize it. We want to\n",
    "1. convert the time axis (horizontal axis) to seconds (as done before for the STFT)\n",
    "2. have physical frequency values [Hz] at the vertical axis, that correspond to the 128 mel bands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cc50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dB compression as before\n",
    "M_dB = librosa.amplitude_to_db(M, ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302829e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = pl.subplots()\n",
    "# note the keyword \"mel\", which indicates that a mel frequency axis is used\n",
    "img = librosa.display.specshow(M_dB, x_axis='time', y_axis='mel', sr=fs, ax=ax, cmap='viridis')\n",
    "fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "ax.set(title='Mel-frequency spectrogram')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147480d",
   "metadata": {},
   "source": [
    "### Constant-Q Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828188b",
   "metadata": {},
   "source": [
    "Let's first check the librosa documentation: https://librosa.org/doc/main/generated/librosa.cqt.html\n",
    "\n",
    "The most important parameters are \n",
    "  - **y** - audio sample vector ($x$)\n",
    "  - **sr** - sampling rate of the audio signal (in Hz)\n",
    "  - **hop_length** - see above (STFT)\n",
    "  - **f_min** - minimum frequency (we can use the default value of 32.70 Hz which corresponds to the note C1)\n",
    "  - **n_bins** - total number of frequency bins (e.g., for a frequency resolution of one bin per semitone and 4 octaves, this would be 4 * 12 = 48)\n",
    "  - **bins_per_octave** - Logarithmic frequency resolution (frequency bins per octave, commonly: 12 or 36)\n",
    "  - **tuning** - Tuning offset (can be used if known tuning frequency of an audio recording deviates from 440 Hz) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3f5c84",
   "metadata": {},
   "source": [
    "We'll now use a short piano recording as running example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_wav = os.path.join(dir_wav, 'piano.wav')  # original filename: 196765__xserra__piano-phrase.wav\n",
    "x, fs = librosa.load(fn_wav)\n",
    "ipd.display(ipd.Audio(data=x, rate=fs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12013e7",
   "metadata": {},
   "source": [
    "Let's compute the CQT for a frequency range of 5 octaves with a resolution of 1 bin per semitone (=12 bins per octave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc210dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_octaves = 5  # let's capture 5 octaves starting from C1\n",
    "bins_per_octave = 12  # let's choose a frequency resolution of 100 cent (= one frequency bin per semitone)\n",
    "C = np.abs(librosa.cqt(x, sr=fs, n_bins=n_octaves*bins_per_octave , bins_per_octave=bins_per_octave))\n",
    "print(\"Shape of CQT:\", C.shape)  # logically, we get 60 frequency bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c709dfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dB magnitude scaling\n",
    "C = librosa.amplitude_to_db(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2524944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use again the visualization tool provided by librosa\n",
    "fig, ax = pl.subplots()\n",
    "img = librosa.display.specshow(C, sr=fs, x_axis='time', y_axis='cqt_note', ax=ax)\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82210372",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "- the time resolution improves for higher frequencies (see lecture)\n",
    "- for all pitches, we observe a similar energy pattern along the frequency axis (just shifted vertically according to the pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4447b0",
   "metadata": {},
   "source": [
    "Now let's do the same for a finer frequency resolution (5 bins per semitone, 60 bins per octave). This will give us finer spectral peaks for the fundamental frequency and the partial frequencies.\n",
    "\n",
    "If you analyze audio recordings with fundamental frequency modulations (such as vibrato in singing recordings), it's always recommended to use higher frequency resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03c93e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_per_octave = 50\n",
    "C = np.abs(librosa.cqt(x, sr=fs, n_bins=n_octaves*bins_per_octave , bins_per_octave=bins_per_octave))\n",
    "print(\"Shape of CQT:\", C.shape)\n",
    "C = librosa.amplitude_to_db(C)\n",
    "fig, ax = pl.subplots()\n",
    "img = librosa.display.specshow(C, sr=fs, x_axis='time', y_axis='cqt_note', ax=ax)\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee6a92",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f3460",
   "metadata": {},
   "source": [
    "Done :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
